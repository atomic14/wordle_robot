{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from enum import Enum\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"images/foo.jpg\")\n",
    "# read the image from a url\n",
    "url = \"http://wordle.local:8000/grab_frame\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = response.read()\n",
    "# turn into an open cv image\n",
    "img = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "scale = 1024 / img.shape[1]\n",
    "resized = cv2.resize(img, (int(img.shape[1] * scale), int(img.shape[0] * scale)))\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "print(gray.shape)\n",
    "plt.imshow(gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresholed = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholed.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    plt.imshow(thresholed, cmap=\"gray\")\n",
    "\n",
    "    for c in contours:\n",
    "        # compute the center of the contour, then detect the name of the\n",
    "        # shape using only the contour\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] != 0:\n",
    "            # get the approximate polygon of the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "            # if we've got four points then it's a rectangle\n",
    "            if len(approx) == 4:\n",
    "                # are the lengths of each side of the rectangle the same?\n",
    "                length_b = cv2.norm(approx[0], approx[1])\n",
    "                length_t = cv2.norm(approx[2], approx[3])\n",
    "                length_l = cv2.norm(approx[0], approx[3])\n",
    "                length_r = cv2.norm(approx[1], approx[2])\n",
    "                if (\n",
    "                    length_l > 0.9 * length_r\n",
    "                    and length_l < 1.1 * length_r\n",
    "                    and length_t > 0.9 * length_b\n",
    "                    and length_t < 1.1 * length_b\n",
    "                    and length_l > 0.1 * image.shape[1]\n",
    "                    and length_r > 0.1 * image.shape[1]\n",
    "                    and length_t > 0.1 * image.shape[0]\n",
    "                    and length_b > 0.1 * image.shape[0]\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"rectangle l={length_l}, r={length_r}, t={length_t}, b={length_b}\"\n",
    "                    )\n",
    "                    # draw the contour and label the shape\n",
    "                    # cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "                    rect = cv2.minAreaRect(\n",
    "                        c\n",
    "                    )  # get a rectangle rotated to have minimal area\n",
    "                    box = cv2.boxPoints(rect)  # get the box from the rectangle\n",
    "                    box = np.int0(box)\n",
    "                    cv2.line(image, tuple(box[0]), tuple(box[1]), (255, 0, 0), 2)\n",
    "                    cv2.line(image, tuple(box[1]), tuple(box[2]), (0, 0, 255), 2)\n",
    "                    cv2.line(image, tuple(box[2]), tuple(box[3]), (255, 0, 0), 2)\n",
    "                    cv2.line(image, tuple(box[3]), tuple(box[0]), (0, 0, 255), 2)\n",
    "\n",
    "                    # work out the bottom left corner of the rectangle - just use the manhattan distance from the 0,0\n",
    "                    bottom_left = box[0]\n",
    "                    bottom_left_distance = 1e9\n",
    "                    top_right = box[0]\n",
    "                    top_right_distance = 0\n",
    "                    top_left = box[0]\n",
    "                    top_left_distance = 1e9\n",
    "                    bottom_right = box[0]\n",
    "                    bottom_right_distance = 1e9\n",
    "                    for point in box:\n",
    "                        # top right and bottom left we can just use the manhattan distance from 0,0\n",
    "                        distance = abs(point[0]) + abs(point[1])\n",
    "                        if distance < bottom_left_distance:\n",
    "                            bottom_left_distance = distance\n",
    "                            bottom_left = point\n",
    "                        if distance > top_right_distance:\n",
    "                            top_right_distance = distance\n",
    "                            top_right = point\n",
    "                        # top left is the manhattan distance from 0, height\n",
    "                        distance = abs(point[0]) + abs(image.shape[0] - point[1])\n",
    "                        if distance < top_left_distance:\n",
    "                            top_left_distance = distance\n",
    "                            top_left = point\n",
    "                        # bottom right is the manhattan distance from width, 0\n",
    "                        distance = abs(image.shape[1] - point[0]) + abs(point[1])\n",
    "                        if distance < bottom_right_distance:\n",
    "                            bottom_right_distance = distance\n",
    "                            bottom_right = point\n",
    "\n",
    "                    print(\"top_right\", top_right)\n",
    "                    print(\"bottom_left\", bottom_left)\n",
    "                    print(\"top_left\", top_left)\n",
    "                    print(\"bottom_right\", bottom_right)\n",
    "\n",
    "                    return top_right, bottom_left, top_left, bottom_right\n",
    "    return None, None, None, None\n",
    "\n",
    "\n",
    "top_right, bottom_left, top_left, bottom_right = find_corners(resized)\n",
    "\n",
    "# get the affine transform that maps from the rectangle we've found to the iphone screen\n",
    "SCREEN_WIDTH = 1170\n",
    "SCREEN_HEIGHT = 2532 - (404 + 140)\n",
    "\n",
    "image_points = np.float32([bottom_left, bottom_right, top_right])\n",
    "screen_points = np.float32([(0, 0), (SCREEN_WIDTH, 0), (SCREEN_WIDTH, SCREEN_HEIGHT)])\n",
    "phone_transform = cv2.getAffineTransform(screen_points, image_points)\n",
    "\n",
    "# draw circles where we think the corners of the phone are\n",
    "result = resized.copy()\n",
    "bl_x, bl_y = cv2.transform(np.array([[[0, 0]]]), phone_transform).squeeze()\n",
    "br_x, br_y = cv2.transform(np.array([[[SCREEN_WIDTH, 0]]]), phone_transform).squeeze()\n",
    "tl_x, tl_y = cv2.transform(np.array([[[0, SCREEN_HEIGHT]]]), phone_transform).squeeze()\n",
    "tr_x, tr_y = cv2.transform(\n",
    "    np.array([[[SCREEN_WIDTH, SCREEN_HEIGHT]]]), phone_transform\n",
    ").squeeze()\n",
    "cv2.circle(result, (bl_x, bl_y), 5, (0, 0, 255), -1)\n",
    "cv2.circle(result, np.int0((br_x, br_y)), 5, (255, 0, 0), -1)\n",
    "cv2.circle(result, np.int0((tl_x, tl_y)), 5, (0, 255, 0), -1)\n",
    "cv2.circle(result, np.int0((tr_x, tr_y)), 5, (255, 255, 0), -1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb, aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the purple circle in the image - this is our 0,0 point\n",
    "\n",
    "hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_purple = np.array([160, 100, 100])\n",
    "upper_purple = np.array([170, 255, 255])\n",
    "mask = cv2.inRange(hsv, lower_purple, upper_purple)\n",
    "mask = cv2.erode(mask, None, iterations=2)\n",
    "result = resized.copy()\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    mask.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    ")\n",
    "for c in contours:\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        if cY < resized.shape[0] * 0.3:\n",
    "            cv2.circle(result, (cX, cY), 5, (255, 0, 0), -1)\n",
    "\n",
    "# locate the 0,0 circle - it's the one in the top right\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb, cmap=\"gray\", aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_polygon(row, col, transform):\n",
    "    # some magic constants from roughly measuring a screenshot\n",
    "    GRID_START_X = 107\n",
    "    GRID_START_Y = 193\n",
    "    GRID_SIZE_X = 160\n",
    "    GRID_SPACING_X = 40\n",
    "    GRID_SIZE_Y = 160\n",
    "    GRID_SPACING_Y = 40\n",
    "\n",
    "    g1_x = GRID_START_X + col * (GRID_SIZE_X + GRID_SPACING_X)\n",
    "    g1_y = GRID_START_Y + row * (GRID_SIZE_Y + GRID_SPACING_Y)\n",
    "    bl1_x, bl1_y = cv2.transform(\n",
    "        np.array([[[int(g1_x), int(g1_y)]]]), transform\n",
    "    ).squeeze()\n",
    "    bl2_x, bl2_y = cv2.transform(\n",
    "        np.array([[[int(g1_x + GRID_SIZE_X), int(g1_y)]]]), transform\n",
    "    ).squeeze()\n",
    "    bl3_x, bl3_y = cv2.transform(\n",
    "        np.array([[[int(g1_x + GRID_SIZE_X), int(g1_y + GRID_SIZE_Y)]]]),\n",
    "        transform,\n",
    "    ).squeeze()\n",
    "    bl4_x, bl4_y = cv2.transform(\n",
    "        np.array([[[int(g1_x), int(g1_y + GRID_SIZE_Y)]]]), transform\n",
    "    ).squeeze()\n",
    "    return np.array(\n",
    "        [\n",
    "            (int(bl1_x), int(bl1_y)),\n",
    "            (int(bl2_x), int(bl2_y)),\n",
    "            (int(bl3_x), int(bl3_y)),\n",
    "            (int(bl4_x), int(bl4_y)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_key_coords(key, transform):\n",
    "    KEY_ROWS = [\n",
    "        [\"q\", \"w\", \"e\", \"r\", \"t\", \"y\", \"u\", \"i\", \"o\", \"p\"],\n",
    "        [\"a\", \"s\", \"d\", \"f\", \"g\", \"h\", \"j\", \"k\", \"l\"],\n",
    "        [\"z\", \"x\", \"c\", \"v\", \"b\", \"n\", \"m\"],\n",
    "    ]\n",
    "    # some magic constants from roughly measuring a screenshot\n",
    "    KEYBOARD_KEY_SPACE_X = 17\n",
    "    KEYBOARD_KEY_HEIGHT = 174\n",
    "\n",
    "    KEY_ROW_X = [40, 73, 190]\n",
    "    KEY_ROW_Y = [1390, 1583, 1780]\n",
    "    KEY_WIDTH = [95, 99, 99]\n",
    "\n",
    "    KEYBOARD_ENTER_KEY_X = 23\n",
    "    KEYBOARD_ENTER_KEY_Y = 1780\n",
    "    KEYBOARD_ENTER_KEY_WIDTH = 147\n",
    "    KEYBOARD_ENTER_KEY_HEIGHT = 170\n",
    "\n",
    "    # special handling for the enter key\n",
    "    if key == \"\\n\":\n",
    "        key_x = KEYBOARD_ENTER_KEY_X + KEYBOARD_ENTER_KEY_WIDTH / 2\n",
    "        key_y = KEYBOARD_ENTER_KEY_Y + KEYBOARD_ENTER_KEY_HEIGHT / 2\n",
    "        return cv2.transform(\n",
    "            np.array([[[int(key_x), int(key_y)]]]), transform\n",
    "        ).squeeze()\n",
    "\n",
    "    # find the key in the keyboard\n",
    "    for row_idx, row in enumerate(KEY_ROWS):\n",
    "        if key in row:\n",
    "            key_idx = row.index(key)\n",
    "            key_x = (\n",
    "                KEY_ROW_X[row_idx]\n",
    "                + key_idx * (KEY_WIDTH[row_idx] + KEYBOARD_KEY_SPACE_X)\n",
    "                + KEY_WIDTH[row_idx] / 2\n",
    "            )\n",
    "            key_y = KEY_ROW_Y[row_idx] + KEYBOARD_KEY_HEIGHT / 2\n",
    "            return cv2.transform(\n",
    "                np.array([[[int(key_x), int(key_y)]]]), transform\n",
    "            ).squeeze()\n",
    "\n",
    "\n",
    "marked_up = resized.copy()\n",
    "for col in range(0, 5):\n",
    "    for row in range(0, 6):\n",
    "        poly = get_grid_polygon(row, col, phone_transform)\n",
    "        cv2.fillPoly(marked_up, [poly], (0, 0, 255))\n",
    "\n",
    "for key in \"abcdefghijklmnopqrstuvwxyz\\n\":\n",
    "    key_x, key_y = get_key_coords(key, phone_transform)\n",
    "    cv2.circle(marked_up, (key_x, key_y), 5, (0, 255, 255), -1)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "rgb = rgb = cv2.cvtColor(marked_up, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(marked_up, cmap=\"gray\", aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dominant color within a polygon\n",
    "class PolygonColor(Enum):\n",
    "    NONE = 0\n",
    "    GREEN = 1\n",
    "    ORANGE = 2\n",
    "\n",
    "\n",
    "def get_dominant_color(green_image, orange_image, polygon, threshold):\n",
    "    mask = np.zeros(green_image.shape, dtype=\"uint8\")\n",
    "    cv2.fillPoly(mask, [polygon], 255)\n",
    "    masked_green_img = cv2.bitwise_and(green_image, mask)\n",
    "    masked_orange_img = cv2.bitwise_and(orange_image, mask)\n",
    "    # cound how many pixels are in the masked images\n",
    "    green_pixels = cv2.countNonZero(masked_green_img)\n",
    "    orange_pixels = cv2.countNonZero(masked_orange_img)\n",
    "    if green_pixels > threshold:\n",
    "        return PolygonColor.GREEN\n",
    "    elif orange_pixels > threshold:\n",
    "        return PolygonColor.ORANGE\n",
    "    else:\n",
    "        return PolygonColor.NONE\n",
    "\n",
    "\n",
    "lower_orange = np.array([0, 100, 100])\n",
    "upper_orange = np.array([30, 255, 255])\n",
    "\n",
    "lower_green = np.array([35, 50, 100])\n",
    "upper_green = np.array([75, 255, 255])\n",
    "\n",
    "green_image = cv2.inRange(hsv, lower_green, upper_green)\n",
    "orange_image = cv2.inRange(hsv, lower_orange, upper_orange)\n",
    "\n",
    "for row in range(0, 6):\n",
    "    for col in range(0, 5):\n",
    "        poly = get_grid_polygon(row, col, phone_transform)\n",
    "        color = get_dominant_color(green_image, orange_image, poly, 100)\n",
    "        if color != PolygonColor.NONE:\n",
    "            print(f\"{color} at {row}, {col}\")\n",
    "\n",
    "plt.imshow(green_image, cmap=\"gray\", aspect=\"equal\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f8a41bf754a85ea9c7223b74e9b35ecd57a8e6a17d5eb623a7a5fcfc26c8f62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
